local framework = require("../framework")
local expect = framework.expect
local describe = framework.describe
local parser = require("../../src/parser")

describe("tokenize", function()
	local tokens = parser.tokenize("local x = 1")
	expect(#tokens).toBe(4)
	expect(tokens[1].kind).toBe("keyword")
	expect(tokens[1].value).toBe("local")
	expect(tokens[2].kind).toBe("identifier")
	expect(tokens[2].value).toBe("x")
	expect(tokens[3].kind).toBe("symbol")
	expect(tokens[3].value).toBe("=")
	expect(tokens[4].kind).toBe("number")
	expect(tokens[4].value).toBe("1")

	tokens = parser.tokenize("function test() end")
	expect(#tokens).toBe(5)
	expect(tokens[1].value).toBe("function")
	expect(tokens[2].value).toBe("test")
	expect(tokens[3].value).toBe("(")
	expect(tokens[4].value).toBe(")")
	expect(tokens[5].value).toBe("end")
end)

describe("tokenize with strings", function()
	local tokens = parser.tokenize('"hello world"')
	expect(#tokens).toBe(1)
	expect(tokens[1].kind).toBe("string")

	tokens = parser.tokenize("'single quoted'")
	expect(#tokens).toBe(1)
	expect(tokens[1].kind).toBe("string")
end)

describe("tokenize with escaped quotes", function()
	local tokens = parser.tokenize('"hello\\"world"')
	expect(#tokens).toBe(1)
	expect(tokens[1].kind).toBe("string")
end)

describe("tokenize with comments", function()
	local tokens = parser.tokenize("local x = 1 -- comment")
	expect(tokens[4].value).toBe("1")
	expect(#tokens).toBe(4)
end)

describe("tokenize with block comments", function()
	local tokens = parser.tokenize("local x = 1 --[[comment]] + 2")
	expect(#tokens).toBe(6)
	expect(tokens[1].value).toBe("local")
	expect(tokens[4].value).toBe("1")
	expect(tokens[5].value).toBe("+")
	expect(tokens[6].value).toBe("2")
end)

describe("tokenize with numbers", function()
	local tokens = parser.tokenize("1 2.5 1e10 1E-5")
	expect(#tokens).toBe(4)
	expect(tokens[1].value).toBe("1")
	expect(tokens[2].value).toBe("2.5")
	expect(tokens[3].value).toBe("1e10")
	expect(tokens[4].value).toBe("1E-5")
end)

describe("tokenize with operators", function()
	local tokens = parser.tokenize("a == b and c ~= d or e <= f")
	expect(tokens[2].value).toBe("==")
	expect(tokens[4].value).toBe("and")
	expect(tokens[6].value).toBe("~=")
	expect(tokens[8].value).toBe("or")
	expect(tokens[10].value).toBe("<=")
end)

describe("tokenize with ellipsis", function()
	local tokens = parser.tokenize("function f(...) end")
	expect(#tokens).toBe(6)
	expect(tokens[4].value).toBe("...")
end)

describe("tokenize with long strings", function()
	local tokens = parser.tokenize("x = [[hello\nworld]]")
	expect(#tokens).toBe(3)
	expect(tokens[1].value).toBe("x")
	expect(tokens[2].value).toBe("=")
	expect(tokens[3].kind).toBe("string")
end)

describe("tokenize empty string", function()
	local tokens = parser.tokenize("")
	expect(#tokens).toBe(0)
end)

describe("tokenize only whitespace", function()
	local tokens = parser.tokenize("   \n  \t  ")
	expect(#tokens).toBe(0)
end)